# Assistify

**A multimodal visual-audio companion that empowers seniors to navigate smartphones safely, confidently, and independently.**

---

## Our Mission

Assistify bridges the digital divide for elderly users by transforming complex smartphone interfaces into intuitive, accessible experiences. We believe that technology should empower everyone, regardless of age or technical proficiency, to communicate, access services, and participate fully in digital life.

## The Problem We're Solving

### Digital Exclusion in the Elderly Population

Smartphones have become essential gateways to healthcare, communication, and financial services. Yet for millions of elderly users, these tools remain frustratingly inaccessible. The challenges are real and multifaceted:

- **Dense, Confusing Interfaces**: Modern apps evolve rapidly with ambiguous icons, nested menus, and cluttered screens that demand cognitive and visual agility many seniors struggle with
- **Digital Tasks That Overwhelm**: Simple actions like paying bills, sending photos, or booking appointments require navigation skills that lead to anxiety and avoidance
- **Inadequate Existing Solutions**: Current accessibility features like enlarged text or voice input provide only static, one-dimensional support without contextual awareness
- **Safety Vulnerabilities**: Elderly users are disproportionately targeted by phishing scams, fraudulent links, and misleading prompts that exploit their unfamiliarity with digital threats
- **Loss of Independence**: Digital exclusion forces seniors to depend on others for daily tasks, eroding confidence and autonomy

### The Gap in Current Solutions

Speech-only assistants like Siri or Alexa are passive and limited—they execute voice commands without understanding visual context or adapting to individual users. Traditional accessibility features lack the intelligence to:

- Guide users dynamically through app interfaces
- Prevent critical errors like tapping malicious links
- Understand what appears on-screen in real-time
- Provide personalized, context-aware assistance
- Adapt to individual interaction histories and learning paces

**The core pain point**: Elderly users need multimodal, real-time, contextually aware digital guidance that bridges the cognitive and sensory gap between human intent and machine interface.

---

## Our Solution

### An Intelligent, Context-Aware Digital Companion

Assistify is more than an accessibility tool—it's a **digital caregiver** that sees what users see, understands their intent, and guides them through every step with patience and clarity.

### How Assistify Works Differently

Unlike traditional assistants that operate blindly, Assistify **perceives and comprehends** your smartphone screen in real-time:

#### Visual Intelligence

- Captures and analyzes your screen continuously
- Identifies app types, UI elements, buttons, and interactive regions
- Recognizes text, icons, and layout structure with precision
- Detects suspicious content, scams, and potentially harmful elements

#### Contextual Understanding

- Infers user intent from screen content and dialogue history
- Maps possible actions and prioritizes the most relevant next steps
- Adapts guidance based on the current app and user's goal
- Maintains memory of past interactions for personalized support

#### Multimodal Guidance

- Provides **visual overlays** with highlights, arrows, and bounding boxes that direct attention to the right place
- Delivers **spoken narration** with clear, empathetic, step-by-step instructions
- Generates **conversational explanations** that clarify ambiguous elements and unfamiliar terms
- Creates an **AR-like experience** that seamlessly blends digital assistance with real interface interaction

---

## Core Features & Capabilities

### 1. Real-Time Screen Understanding

Assistify continuously monitors your smartphone screen to identify:

- What app you're using
- What you're trying to accomplish
- Which buttons or options are relevant to your goal
- Potential obstacles or confusing elements

### 2. Conversational Assistance

Engage naturally with Assistify through voice:

- Ask questions like "How do I reply to this message?" or "What does this icon mean?"
- Receive clear, jargon-free explanations
- Get help understanding unfamiliar slang or abbreviations in messages
- Navigate interfaces through natural dialogue

### 3. Safety & Scam Detection

Assistify acts as a protective layer between you and digital threats:

- Detects phishing attempts and fraudulent links
- Warns you before interacting with suspicious prompts
- Identifies misleading advertisements disguised as interface elements
- Prevents accidental deletions or destructive actions

### 4. Personalized Learning

The more you use Assistify, the better it understands you:

- Remembers your preferences and common tasks
- Adapts explanations to your learning pace
- Recognizes your interaction patterns
- Becomes increasingly efficient at predicting your needs

### 5. Cross-App Continuity

Assistify follows you throughout your phone:

- Provides consistent guidance across different apps
- Maintains context when you switch between applications
- Helps you navigate complex workflows that span multiple apps
- Never leaves your side during multi-step tasks

---

## Use Cases & Real-World Scenarios

### Communication & Social Connection

**Messaging Family & Friends**

- "How do I send a photo to my daughter?"
- Assistify identifies the messaging app, highlights the attachment icon, guides you through photo selection, and confirms before sending

**Video Calling Grandchildren**

- "I want to video call my grandson"
- Step-by-step guidance through opening the app, finding the contact, and initiating the call with confidence

**Understanding Modern Slang**

- Receives a message with unfamiliar abbreviations or emoji
- Assistify explains what "LOL" means or clarifies the tone of a message

### Healthcare Access

**Booking Medical Appointments**

- Navigating complex healthcare provider apps
- Guided through date selection, insurance information entry, and appointment confirmation

**Medication Reminders & Information**

- Understanding prescription app interfaces
- Finding medication details, refill options, and pharmacy locations

**Telehealth Consultations**

- Joining video appointments with medical providers
- Ensuring camera, microphone, and connection are working properly

### Financial Services

**Mobile Banking Tasks**

- Checking account balances safely
- Transferring money between accounts with confirmation prompts
- Understanding transaction histories and statements

**Bill Payments**

- Navigating utility company apps
- Entering payment information securely
- Verifying amounts before confirming payments

**Fraud Prevention**

- Detecting suspicious payment requests
- Warning against phishing attempts disguised as bank notifications
- Confirming legitimacy of financial communications

### Daily Living & Independence

**Online Shopping**

- Browsing products, reading reviews, and comparing options
- Adding items to cart and completing checkout processes
- Tracking deliveries and managing orders

**Transportation & Navigation**

- Booking rideshare services like Uber or Lyft
- Using map applications to find locations
- Understanding arrival times and driver information

**Entertainment & Hobbies**

- Navigating streaming services to watch shows
- Managing music apps and playlists
- Exploring new apps for hobbies and interests

---

## Value Highlights

### Human-Centered Accessibility

Converts complex digital environments into intuitive, step-by-step visual and audio cues tailored for senior users' cognitive and sensory needs.

### Contextual Awareness

Understands live screen context to deliver relevant, timely guidance instead of generic, one-size-fits-all instructions that don't match the current situation.

### Safety Layer

Actively protects users from digital threats, preventing misclicks on malicious content and improving trust in digital interactions.

### Confidence Building

Empowers elderly users to attempt new tasks independently, reducing anxiety and building digital literacy through supportive, patient guidance.

### Personalized Experience

Adapts based on individual behavioral patterns and learning pace, creating a truly "digital caregiver" experience that respects each user's unique needs.

### Dignity & Independence

Reduces dependence on family members or caregivers for basic digital tasks, preserving autonomy and self-sufficiency.

---

## Why This Matters

### The Demographic Reality

Global populations are aging rapidly. By 2050, the number of people aged 60+ will double to over 2 billion. This demographic shift creates urgent need for age-inclusive technology.

### The Cost of Digital Exclusion

When elderly individuals cannot access digital services:

- Healthcare becomes harder to manage
- Social connections weaken
- Financial independence erodes
- Quality of life diminishes
- Societal care burdens increase

### The Opportunity for Technology

Modern AI possesses the multimodal capabilities needed to solve this problem. What was impossible five years ago—real-time screen understanding, contextual reasoning, and adaptive guidance—is now achievable.

Assistify represents a commitment to using these capabilities for profound social good.

---

## Beyond Seniors: A Platform for Universal Accessibility

While our initial focus is elderly users, Assistify's core capabilities have potential to serve:

- **Users with visual impairments** who need detailed screen descriptions and navigation assistance
- **Individuals with cognitive disabilities** who benefit from simplified, step-by-step guidance
- **Non-native speakers** navigating interfaces in unfamiliar languages
- **Anyone learning new technology** who wants patient, judgment-free support
- **Users in high-stress situations** who need clear guidance under pressure

Assistify represents a new paradigm: **Contextually aware, multimodal AI assistance that meets users wherever they are.**

---

## Technical Documentation

### Project Structure Overview

The Assistify Flutter application follows a clean, modular architecture organized by feature and responsibility. This section provides a comprehensive guide to the codebase structure, making it easy for developers and AI agents to understand where to find and modify code.

```
lib/
├── main.dart                    # App entry point and initialization
├── constants/                   # Design system constants
│   ├── colors.dart            # Color palette and theme colors
│   ├── dimensions.dart        # Spacing, sizes, and responsive utilities
│   └── text_styles.dart       # Typography system
├── models/                     # Data models and business logic
│   ├── conversation.dart      # Conversation history model
│   ├── message.dart           # Individual message/speech segment model
│   ├── preferences.dart       # User preferences model
│   └── screen_recording.dart  # Screen recording metadata model
├── providers/                  # State management (Provider pattern)
│   └── app_state_provider.dart # Central app state provider
├── screens/                    # Full-screen UI components
│   ├── home_screen.dart       # Main home screen with voice agent
│   ├── settings_screen.dart   # Settings and preferences screen
│   ├── history_screen.dart    # Conversation history screen
│   └── screen_recording_history_screen.dart # Screen recording history
├── services/                   # Business logic and platform integration
│   ├── permission_service.dart # Permission handling (mic, screen recording)
│   ├── recording_service.dart  # Screen recording via platform channels
│   ├── speech_service.dart     # Speech recognition via platform channels
│   └── storage_service.dart    # Local data persistence (SharedPreferences)
├── utils/                      # Utility functions and helpers
│   └── localization_helper.dart # Localization utilities
├── widgets/                    # Reusable UI components
│   ├── voice_agent_circle.dart # Animated voice agent circle widget
│   ├── control_button.dart    # Control button component
│   ├── onboarding_flow.dart   # Onboarding permission flow
│   ├── permission_modal.dart  # Permission request modal
│   └── screen_recording_card.dart # Screen recording card widget
└── l10n/                       # Localization files
    ├── app_en.arb             # English translations
    ├── app_zh.arb             # Chinese translations
    └── app_localizations*.dart # Generated localization code
```

### Architecture Patterns

#### State Management: Provider Pattern
The app uses the **Provider** package for state management. All app state is centralized in `AppStateProvider` (`lib/providers/app_state_provider.dart`), which:
- Manages UI state (chat active, recording active, microphone muted)
- Handles permission states
- Stores user preferences
- Manages conversation and recording history
- Coordinates between services

**Key Pattern**: The `AppStateProvider` acts as the single source of truth. Services handle platform-specific operations, while the provider manages the app's reactive state.

#### Service Layer Pattern
Services encapsulate platform-specific functionality and business logic:
- **PermissionService**: Handles permission requests using `permission_handler`
- **RecordingService**: Manages screen recording via platform channels (iOS ReplayKit)
- **SpeechService**: Handles speech recognition via platform channels (iOS SFSpeechRecognizer)
- **StorageService**: Manages local persistence using SharedPreferences

**Key Pattern**: Services are injected into `AppStateProvider` via constructor injection, allowing for easy testing and mocking.

#### Model Layer
Data models are immutable and include:
- JSON serialization/deserialization
- Helper methods for formatting (dates, durations, file sizes)
- Business logic related to the data structure

### Detailed Component Guide

#### Entry Point: `lib/main.dart`
**Purpose**: Application initialization and root widget setup

**Key Components**:
- `AssistifyApp`: Root MaterialApp widget with theme configuration
- `AppInitializer`: Handles app initialization and onboarding flow
- Sets up Provider, localization, and text scaling based on preferences

**When to Modify**:
- Adding new app-wide configuration
- Changing theme or Material Design settings
- Modifying initialization flow

#### State Management: `lib/providers/app_state_provider.dart`
**Purpose**: Central state management hub

**Key Responsibilities**:
- Permission state management (screen recording, microphone, speech)
- Chat session lifecycle (start, mute/unmute, end)
- Screen recording lifecycle (start, stop)
- User preferences management
- Conversation and recording history management
- Audio level monitoring from speech service

**Key Methods**:
- `initialize()`: Loads state from storage on app start
- `startChat()`: Begins a chat session with speech recognition
- `endChat()`: Ends chat and saves conversation to history
- `toggleScreenRecording()`: Starts/stops screen recording
- `updatePreferences()`: Updates user preferences and restarts services if needed

**When to Modify**:
- Adding new app state
- Changing state management logic
- Adding new user actions

#### Services Layer

##### `lib/services/permission_service.dart`
**Purpose**: Platform-agnostic permission handling

**Key Features**:
- Microphone permission checking and requesting
- Screen recording permission (iOS ReplayKit handles natively)
- Permission state mapping to app's enum
- Settings app navigation for permanently denied permissions

**When to Modify**:
- Adding new permission types
- Changing permission request flow
- Platform-specific permission handling

##### `lib/services/recording_service.dart`
**Purpose**: Screen recording via platform channels

**Platform Channels**:
- Method Channel: `com.assistify/screen_recording`
- Methods: `startRecording`, `stopRecording`, `isAvailable`, `isRecording`

**Key Features**:
- iOS: Uses ReplayKit for screen recording
- Android: MediaProjection (to be implemented)
- Returns recording metadata (file path, duration, file size)

**When to Modify**:
- Adding new recording features
- Implementing Android support
- Changing recording format or quality

##### `lib/services/speech_service.dart`
**Purpose**: Speech recognition via platform channels

**Platform Channels**:
- Method Channel: `com.assistify/speech_recognition`
- Event Channel: `com.assistify/audio_levels` (real-time audio levels)
- Event Channel: `com.assistify/speech_events` (speech recognition events)

**Key Features**:
- iOS: Uses SFSpeechRecognizer
- Real-time audio level streaming
- Speech event streaming (segment completion on silence)
- Multi-language support (en-US, zh-Hans)

**When to Modify**:
- Adding new speech recognition features
- Changing language support
- Modifying audio level processing

##### `lib/services/storage_service.dart`
**Purpose**: Local data persistence

**Storage Keys**:
- `onboarding_complete`: Boolean flag
- `screen_recording_permission`: Boolean flag
- `microphone_permission`: Boolean flag
- `user_preferences`: JSON string
- `conversations`: JSON array
- `screen_recordings`: JSON array

**When to Modify**:
- Adding new stored data types
- Changing storage format
- Migrating data structures

#### Models Layer

##### `lib/models/preferences.dart`
**Purpose**: User preferences model

**Properties**:
- `largeTextEnabled`: Increases text size (1.2x scale)
- `slowerSpeechEnabled`: Reduces speech speed (future feature)
- `highContrastEnabled`: Increases contrast (future feature)
- `useSimplifiedChinese`: Switches language to Simplified Chinese

**Computed Properties**:
- `textScaleFactor`: Returns 1.2 if large text enabled, else 1.0
- `languageCode`: Returns 'zh-Hans' for Chinese, 'en-US' for English

**When to Modify**:
- Adding new preference options
- Changing preference behavior

##### `lib/models/conversation.dart`
**Purpose**: Conversation history model

**Properties**:
- `id`: Unique identifier
- `timestamp`: When conversation started
- `previewText`: First 100 characters for list view
- `duration`: Conversation length
- `fullTranscript`: Complete transcript (optional)
- `messages`: List of individual speech segments

**Helper Methods**:
- `formattedDateTime`: Human-readable date/time
- `formattedDuration`: "X min Y sec" format

**When to Modify**:
- Adding new conversation metadata
- Changing conversation structure

##### `lib/models/message.dart`
**Purpose**: Individual speech segment model

**Properties**:
- `id`: Unique identifier
- `text`: Speech transcript
- `timestamp`: When message was captured

**When to Modify**:
- Adding message metadata (e.g., confidence scores)
- Changing message structure

##### `lib/models/screen_recording.dart`
**Purpose**: Screen recording metadata model

**Properties**:
- `id`: Unique identifier
- `filePath`: Path to video file
- `timestamp`: When recording was created
- `duration`: Recording length
- `fileSize`: File size in bytes

**Helper Methods**:
- `formattedSize`: Human-readable file size (KB, MB)
- `formattedDuration`: "MM:SS" format

**When to Modify**:
- Adding recording metadata
- Changing recording structure

#### Screens Layer

##### `lib/screens/home_screen.dart`
**Purpose**: Main application screen

**Layout Structure**:
- App Bar: Title and settings button
- Voice Agent Section (75%): Animated voice agent circle with gradient background
- Control Section (25%): Three control buttons (Chat, Microphone, Screen Recording)

**Key Features**:
- Responsive sizing based on screen width
- Real-time audio level visualization
- State-driven UI updates via Consumer

**When to Modify**:
- Changing home screen layout
- Adding new controls
- Modifying voice agent display

##### `lib/screens/settings_screen.dart`
**Purpose**: Settings and preferences screen

**Sections**:
- Conversation History: Link to history screen
- Screen Recording History: Link to recording history
- Preferences: Toggle switches for all user preferences
- About: App info and links (privacy, terms, feedback)

**When to Modify**:
- Adding new settings options
- Changing settings UI
- Adding new navigation links

##### `lib/screens/history_screen.dart`
**Purpose**: Conversation history display

**Features**:
- List of past conversations
- Empty state when no conversations
- Tap to view conversation detail
- Long press to delete conversation
- Conversation detail screen with message bubbles

**When to Modify**:
- Changing history display format
- Adding conversation filtering/search
- Modifying conversation detail view

##### `lib/screens/screen_recording_history_screen.dart`
**Purpose**: Screen recording history display

**Features**:
- List of past recordings
- Empty state when no recordings
- Uses `ScreenRecordingCard` widget for each item

**When to Modify**:
- Changing recording display format
- Adding recording filtering/search

#### Widgets Layer

##### `lib/widgets/voice_agent_circle.dart`
**Purpose**: Animated voice agent circle with breathing and audio-reactive effects

**Animations**:
- Breathing animation: Continuous subtle scale pulsing
- Activation animation: Color transition, rotation, and scale on chat start
- Audio-reactive: Scale and color intensity based on audio levels
- Ripple rings: Outer rings that pulse with audio

**States**:
- Resting: Grey colors, subtle breathing
- Active: Blue colors, enhanced animations, audio-reactive

**When to Modify**:
- Changing animation behavior
- Modifying visual appearance
- Adding new animation states

##### `lib/widgets/control_button.dart`
**Purpose**: Reusable control button with icon and label

**Features**:
- Circular button with icon
- Label text below
- Pulse animation for active states
- Press feedback with scale animation
- Haptic feedback on tap

**When to Modify**:
- Changing button appearance
- Adding new button states
- Modifying animations

##### `lib/widgets/onboarding_flow.dart`
**Purpose**: First-time user onboarding flow

**Flow Steps**:
1. Screen Recording Permission: Explains why screen access is needed
2. Microphone Permission: Explains why microphone access is needed
3. Success Confirmation: Confirms setup completion

**Features**:
- Sequential permission requests
- Handles permanently denied permissions
- Shows error dialogs if permissions denied

**When to Modify**:
- Adding new onboarding steps
- Changing permission request order
- Modifying onboarding UI

##### `lib/widgets/permission_modal.dart`
**Purpose**: Reusable permission request modal

**Features**:
- Customizable icon, title, description
- Animated appearance (fade + scale)
- Non-dismissible (must interact with button)

**When to Modify**:
- Changing modal appearance
- Adding new modal types

##### `lib/widgets/screen_recording_card.dart`
**Purpose**: Card widget for displaying screen recordings

**Features**:
- Video player with play/pause
- Recording metadata (date, duration, file size)
- Delete button with confirmation
- Lazy video initialization (only loads when played)

**When to Modify**:
- Changing recording display format
- Adding new actions
- Modifying video player behavior

#### Constants Layer

##### `lib/constants/colors.dart`
**Purpose**: Design system color palette

**Color Categories**:
- Primary Colors: Blue, coral, grey, green
- Neutral Colors: Background, card, text colors
- Interactive States: Button colors, hover, disabled
- Gradient Colors: Voice agent section gradients
- Voice Agent Colors: Active and inactive states

**When to Modify**:
- Changing app color scheme
- Adding new color variants

##### `lib/constants/dimensions.dart`
**Purpose**: Spacing, sizing, and responsive utilities

**Categories**:
- Spacing System: xs, sm, md, lg, xl, xxl (multiples of 8)
- Border Radius: Small to XLarge
- Component Sizes: Voice agent circle, control buttons
- Responsive Utilities: Functions that adjust sizes based on screen width

**Key Methods**:
- `getVoiceAgentCircleSize()`: Responsive circle size
- `getControlButtonSize()`: Responsive button size
- `getPaddingMultiplier()`: Responsive padding multiplier

**When to Modify**:
- Changing spacing system
- Adjusting component sizes
- Modifying responsive breakpoints

##### `lib/constants/text_styles.dart`
**Purpose**: Typography system

**Text Styles**:
- `appTitle`: 28px, semibold
- `heading`: 24px, semibold
- `bodyLarge`: 20px, regular
- `body`: 18px, regular
- `buttonLabel`: 16px, medium
- `caption`: 14px, regular

**Features**:
- Consistent font family (Roboto)
- Text scaling utility method

**When to Modify**:
- Changing typography scale
- Adding new text styles
- Modifying font family

#### Utilities Layer

##### `lib/utils/localization_helper.dart`
**Purpose**: Localization utilities

**Features**:
- Supported locales: English (en), Chinese (zh)
- Localization delegates setup
- Helper to get locale from preferences
- Helper to get AppLocalizations from context

**When to Modify**:
- Adding new languages
- Changing locale detection logic

### Data Flow Patterns

#### Starting a Chat Session
1. User taps "Start Chat" button in `HomeScreen`
2. `AppStateProvider.startChat()` is called
3. Checks microphone permission via `PermissionService`
4. Checks speech recognition permission via `SpeechService`
5. Starts speech recognition via `SpeechService.startListening()`
6. Subscribes to audio level stream for visualization
7. Subscribes to speech event stream for segment completion
8. Updates UI state (`isChatActive = true`)

#### Ending a Chat Session
1. User taps "End Chat" button
2. `AppStateProvider.endChat()` is called
3. Stops speech recognition and gets final transcript
4. Creates `Conversation` model with all messages
5. Saves conversation via `StorageService`
6. Reloads conversations list
7. Resets UI state (`isChatActive = false`)

#### Screen Recording Flow
1. User taps "Share Screen" button
2. `AppStateProvider.toggleScreenRecording()` is called
3. Checks screen recording permission (from storage)
4. If not granted, shows permission modal
5. Calls `RecordingService.startRecording()` via platform channel
6. iOS ReplayKit shows system permission dialog (first time)
7. Recording starts, updates UI state
8. On stop, saves recording metadata to storage

#### Preference Updates
1. User toggles preference in `SettingsScreen`
2. `AppStateProvider.updatePreferences()` is called
3. Saves preferences via `StorageService`
4. If language changed and chat is active, restarts speech recognition
5. Notifies listeners to update UI

### Finding Code for Common Tasks

#### Adding a New Feature
1. **UI Changes**: Look in `lib/screens/` or `lib/widgets/`
2. **State Management**: Add to `AppStateProvider` in `lib/providers/`
3. **Business Logic**: Create or modify service in `lib/services/`
4. **Data Models**: Add or modify models in `lib/models/`
5. **Storage**: Add methods to `StorageService` in `lib/services/`

#### Modifying Permissions
1. **Permission Logic**: `lib/services/permission_service.dart`
2. **Permission UI**: `lib/widgets/permission_modal.dart`
3. **Onboarding**: `lib/widgets/onboarding_flow.dart`
4. **State Management**: `AppStateProvider` permission methods

#### Changing Visual Design
1. **Colors**: `lib/constants/colors.dart`
2. **Spacing/Sizes**: `lib/constants/dimensions.dart`
3. **Typography**: `lib/constants/text_styles.dart`
4. **Theme**: `lib/main.dart` (MaterialApp theme)

#### Adding New Screen
1. Create new file in `lib/screens/`
2. Follow pattern from existing screens (Scaffold, AppBar, Consumer)
3. Add navigation from appropriate screen
4. Use constants for styling (colors, dimensions, text styles)

#### Adding Platform-Specific Code
1. **iOS**: `ios/Runner/` directory (Swift/Objective-C)
2. **Android**: `android/app/src/main/` directory (Kotlin/Java)
3. **Platform Channels**: Define in native code, call from `lib/services/`
4. **Method Channels**: Use `MethodChannel` in Dart services
5. **Event Channels**: Use `EventChannel` for streams

#### Modifying Localization
1. **Translation Files**: `lib/l10n/app_en.arb` and `lib/l10n/app_zh.arb`
2. **Generated Code**: `lib/l10n/app_localizations*.dart` (auto-generated)
3. **Usage**: `LocalizationHelper.of(context).keyName`
4. **Regenerate**: Run `flutter gen-l10n` after modifying ARB files

### Testing Strategy

#### Unit Testing
- Test models: JSON serialization, helper methods
- Test services: Mock platform channels, test business logic
- Test providers: Mock services, test state transitions

#### Widget Testing
- Test individual widgets in isolation
- Test widget interactions and state changes
- Test responsive behavior

#### Integration Testing
- Test complete user flows (chat start → end → save)
- Test permission flows
- Test navigation between screens

### Development Workflow

#### Adding a New Feature
1. **Plan**: Identify which layers need changes (UI, state, service, model)
2. **Model First**: Create or modify data models if needed
3. **Service Layer**: Add business logic to appropriate service
4. **State Management**: Add state and methods to `AppStateProvider`
5. **UI Layer**: Create or modify screens/widgets
6. **Storage**: Add persistence if needed
7. **Localization**: Add strings to ARB files
8. **Test**: Write tests for new functionality

#### Debugging Tips
- **State Issues**: Check `AppStateProvider` and service subscriptions
- **Permission Issues**: Check `PermissionService` and platform-specific code
- **UI Issues**: Check widget rebuilds and Consumer usage
- **Platform Channel Issues**: Check native code and channel names match

### Key Dependencies

- **provider**: State management
- **shared_preferences**: Local storage
- **permission_handler**: Permission management
- **video_player**: Video playback for recordings
- **intl**: Date/time formatting
- **audioplayers**: Audio playback (future feature)
- **flutter_localizations**: Localization support

### Platform-Specific Notes

#### iOS
- Screen Recording: Uses ReplayKit (permission dialog appears on first use)
- Speech Recognition: Uses SFSpeechRecognizer
- Platform Channels: Defined in `ios/Runner/AppDelegate.swift`

#### Android
- Screen Recording: MediaProjection (to be implemented)
- Speech Recognition: To be implemented
- Platform Channels: Defined in `android/app/src/main/` Kotlin files

### Code Style Guidelines

- **Naming**: Use descriptive names, follow Dart conventions
- **Imports**: Group imports (dart, package, relative)
- **Comments**: Document public APIs and complex logic
- **Formatting**: Use `dart format` before committing
- **Widgets**: Extract reusable widgets to `lib/widgets/`
- **Constants**: Use constants from `lib/constants/` instead of magic numbers

---

_Powered by advanced multimodal AI that sees, understands, and guides—transforming digital accessibility from a feature into a fundamental right._
